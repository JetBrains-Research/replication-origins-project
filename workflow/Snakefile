import pandas as pd
import os

configfile: 'config/config.yaml'

SAMPLES_INFO = pd.read_csv(config['data_info'], sep=';')
SAMPLES_INFO.Target = SAMPLES_INFO.Target.fillna('')
SAMPLES_INFO['Samples'] = SAMPLES_INFO.GSM + '_' + SAMPLES_INFO.Cell + '_' + SAMPLES_INFO.Method
SAMPLES_INFO = SAMPLES_INFO.set_index(['Samples'], drop=False)
SAMPLES_INFO.to_csv()
SAMPLES_INFO_INDEX = SAMPLES_INFO.index.tolist()
ind_n = 1
for i, b in enumerate(SAMPLES_INFO.index.duplicated()):
    if b:
        SAMPLES_INFO_INDEX[i] += '_' + str(ind_n)
        ind_n += 1
    else:
        ind_n = 1

SAMPLES_INFO.index = SAMPLES_INFO_INDEX

SAMPLES_INFO['FilePref'] = SAMPLES_INFO.SRX + '/' + SAMPLES_INFO.SRR
SAMPLES_INFO['File'] = SAMPLES_INFO['FilePref'] + '.fastq'

onstart:
    shell(f"mkdir -p {config['tmp_dir']}")

wildcard_constraints:
    genome="[A-Za-z0-9]+",

rule all:
    input:
        # expand(f"data/reads/{{file}}", file=SAMPLES_INFO.File)
        'qc/multiqc/reads.html',
        'qc/multiqc/bams.html',
        expand(
            [
                "bigwigs/{sample}_{genome}.bw",
                "macs2/{sample}_{genome}_peaks.narrowPeak",
                #"span/{sample}_{genome}.span"
            ],
            sample=SAMPLES_INFO.Samples,
            genome=config['genome']
        )

rule get_fastq:
    output:
        "data/reads/{srx}/{accession, [A-Za-z0-9]+}.fastq"
    params:
        tmp_dir = config['tmp_dir'],
        out_dir=lambda wildcards, output: os.path.dirname(output[0])
    log:
        'data/reads/{srx}/{accession, [A-Za-z0-9]+}.fastq.log'
    threads: 8
    conda:
        "envs/bioinf.yaml"
    shell: "parallel-fastq-dump --threads {threads} --outdir {params.out_dir} --sra-id {wildcards.accession} --split-files &> {log}"

rule get_fastq_paired:
    output:
        "data/reads/{srx}/{accession, [A-Za-z0-9]+}_1.fastq",
        "data/reads/{srx}/{accession, [A-Za-z0-9]+}_2.fastq",
    params:
        tmp_dir = config['tmp_dir'],
        out_dir=lambda wildcards, output: os.path.dirname(output[0])
    log:
        'data/reads/{srx}/{accession, [A-Za-z0-9]+}.fastq.log'
        # 'data/reads/{srx}/{accession, [A-Za-z0-9]+}_1.fastq.log',
        # 'data/reads/{srx}/{accession, [A-Za-z0-9]+}_2.fastq.log'
    threads: 8
    conda:
        "envs/bioinf.yaml"
    shell: "parallel-fastq-dump --threads {threads} --outdir {params.out_dir} --sra-id {wildcards.accession} --split-files &> {log}"

rule fastqc:
    input:
        lambda wildcards: f"data/reads/{SAMPLES_INFO.loc[wildcards.sample, 'File']}"
    output:
        html='qc/fastqc/{sample, .*(?<![12])}.html',
        zip='qc/fastqc/{sample, .*(?<![12])}_fastqc.zip'
    log:
        'qc/fastqc/{sample, .*(?<![12])}.html.log'
    params: '--quiet'
    threads: 8
    wrapper:
        '0.73.0/bio/fastqc'

rule fastqc_1:
    input:
        lambda wildcards: f"data/reads/{SAMPLES_INFO.loc[wildcards.sample, 'FilePref']}_1.fastq"
    output:
        html='qc/fastqc/{sample}_1.html',
        zip='qc/fastqc/{sample}_1_fastqc.zip'
    log:
        'qc/fastqc/{sample}_1.html.log'
    params: '--quiet'
    threads: 8
    wrapper:
        '0.73.0/bio/fastqc'

rule fastqc_2:
    input:
        lambda wildcards: f"data/reads/{SAMPLES_INFO.loc[wildcards.sample, 'FilePref']}_2.fastq"
    output:
        html='qc/fastqc/{sample}_2.html',
        zip='qc/fastqc/{sample}_2_fastqc.zip'
    log:
        'qc/fastqc/{sample}_2.html.log'
    params: '--quiet'
    threads: 8
    wrapper:
        '0.73.0/bio/fastqc'

def multiqc_input(wildcards):
    input = []
    path_w = 'qc/fastqc/{sample}{pair}_fastqc.zip'
    for idx, row in SAMPLES_INFO.iterrows():
        if row.Pair == 1:
            input.append(path_w.format(sample=row.Samples, pair='_1'))
            input.append(path_w.format(sample=row.Samples, pair='_2'))
        else:
            input.append(path_w.format(sample=row.Samples, pair=''))
    return input

rule multiqc:
    input:
        # expand('qc/fastqc/{sample}_fastqc.zip', sample=SAMPLES_INFO.Samples)
        multiqc_input
    output:
        'qc/multiqc/reads.html'
    log:
        'qc/multiqc/reads.html.log'
    wrapper:
        '0.73.0/bio/multiqc'

rule download_span:
    output:
        "tools/span-0.13.5244.jar"
    shell:
        "wget https://download.jetbrains.com/biolabs/span/span-0.13.5244.jar -O {output}"

rule download_reference_genome:
    output:
        "indexes/{genome}/{genome}.fa.gz"
    shell:
        "wget http://hgdownload.soe.ucsc.edu/goldenPath/{wildcards.genome}/bigZips/{wildcards.genome}.fa.gz -O {output}"

rule unzip_reference_genome:
    input:
        "indexes/{genome}/{genome}.fa.gz"
    output:
        "indexes/{genome}/{genome}.fa"
    shell:
        "gzip -d -c {input} > {output}"

rule bowtie2_build:
    input:
        reference="indexes/{genome}/{genome}.fa"
    output:
        multiext(
            "indexes/{genome}/{genome}",
            ".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2",
        ),
    log:
        "indexes/{genome}/{genome}.log",
    params:
        basename = lambda wildcards, output: output[0].replace(".1.bt2","")
    conda:
        'envs/bowtie2.yaml'
    threads: 8
    shell:
        "bowtie2-build --threads {threads} {input.reference} {params.basename} &> {log}"

def bowtie2_align_sample(wildcards):
    if SAMPLES_INFO.loc[wildcards.sample, 'Pair'] == 1:
        pref, suf = f"data/reads/{SAMPLES_INFO.loc[wildcards.sample, 'File']}".rsplit('.', 1)
        pref1 = pref + '_1.' + suf
        pref2 = pref + '_2.' + suf
        return [pref1, pref2]
    else:
        return [f"data/reads/{SAMPLES_INFO.loc[wildcards.sample, 'File']}"]

rule bowtie2_align:
    input:
        # sample=lambda wildcards: [f"data/reads/{SAMPLES_INFO.loc[wildcards.sample, 'File']}"],
        sample = bowtie2_align_sample,
        index_files=multiext(
            "indexes/{genome}/{genome}",
            ".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2",
        ),
    output:
        "bams/{sample}_{genome}.bam"
    log:
        "bams/{sample}_{genome}.bam.log"
    params:
        index="indexes/{genome}/{genome}"
    conda:
        'envs/bowtie2.yaml'
    threads: 8
    script:
        'scripts/bowtie2-align.py'

rule multiqc_bowtie2:
    input:
        expand("bams/{sample}_{genome}.bam", sample=SAMPLES_INFO.Samples, genome=config['genome'])
    output:
        'qc/multiqc/bams.html'
    log:
        'qc/multiqc/bams.html.log'
    wrapper:
        '0.73.0/bio/multiqc'

rule samtools_sort_bam:
    input:
        "bams/{sample}_{genome}.bam"
    output:
        "bams/{sample}_{genome}.sorted.bam"
    params:
        extra = "-m 4G",
        tmp_dir = config['tmp_dir']
    threads:  # Samtools takes additional threads through its option -@
        8     # This value - 1 will be sent to -@.
    wrapper:
        "0.73.0/bio/samtools/sort"

rule samtools_index_bam:
    input: "bams/{sample}_{genome}.sorted.bam"
    output: "bams/{sample}_{genome}.sorted.bam.bai"
    log: "bams/{sample}_{genome}.sorted.bam.log"
    wrapper:
        "0.73.0/bio/samtools/index"

rule bam_coverage:
    input:
        bams="bams/{sample}_{genome}.sorted.bam",
        bam_indexes="bams/{sample}_{genome}.sorted.bam.bai"
    output:
       "bigwigs/{sample}_{genome}.bw"
    log:
       "bigwigs/{sample}_{genome}.bw.log"
    conda:
        "envs/bioinf.yaml"
    shell:
        "bamCoverage --bam {input.bams} -o {output} &> {log}"

rule macs2:
    input:
        treatment="bams/{sample}_{genome}.sorted.bam",   # required: treatment sample(s)
    output:
        multiext("macs2/{sample}_{genome}",
                 "_peaks.xls",   ### required
                 ### optional output files
                 "_peaks.narrowPeak",
                 "_summits.bed"
                 )
    log:
        "macs2/{sample}_{genome}.log"
    params:
        "-f BAM -g hs --nomodel"
    wrapper:
        "0.73.0/bio/macs2/callpeak"

rule download_chrom_sizes:
    output: "indexes/{genome}/{genome}.chrom.sizes"
    log: "indexes/{genome}/{genome}.chrom.sizes.log"
    # TODO: use ucsc tool, which fetch chrom sizes
    shell:
        'wget -O {output} http://hgdownload.cse.ucsc.edu/goldenPath/{wildcards.genome}/bigZips/{wildcards.genome}.chrom.sizes &> {log}'

rule call_peaks_span:
    input:
        span=rules.download_span.output,
        signal="bams/{sample}_{genome}.sorted.bam",
        chrom_sizes=rules.download_chrom_sizes.output
    output:
        #peaks='span/{sample}_{genome}.peak',
        model='span/{sample}_{genome}.span'

    log: 'span/{sample}_{genome}.log'
    conda: 'envs/java8.env.yaml'
    threads: 4
    params:
        span_params=config['span_params'],
    shell:
         # '--bin {wildcards.bin} --fdr {wildcards.fdr} --gap {wildcards.gap} --peaks {output.peaks}'
         'java -Xmx8G -jar {input.span} analyze -t {input.signal} --chrom.sizes {input.chrom_sizes} '
         '--model {output.model} --fragment 0 '
         '--workdir span --threads {threads} '
         '{params.span_params} &> {log}'